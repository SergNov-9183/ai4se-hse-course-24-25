## Практическое задание на тему "Классификация комментариев на ревью"

Для того, чтобы не загромождать решение я удалил многие Outputs блоков, для получения результатов необходимо запустить блоки.
Надеюсь, ничего критичного в этом нет)

### Описание задания

Цель данного задания - разработать программное решение на языке Python для
классификации рецензий исходного кода.

Примеры токсичных комментариев:

```
 - doh. its awful! it should not be our work...
 - Chris, just a question about 'intrusive', how can I understand it? Why it sucks.
```

Примеры не токсичных комментариев:
```
 - Please, remove indention of commit message.
 - Here should be admin_snapshots_client.reset_snapshot_status
```

### Подзадача 1: Подготовка набора данных

#### Описание

**Цель**: Подготовка набора данных, содержащего размеченные рецензии исходного
кода из репозитория [**ToxiCR**](https://github.com/WSU-SEAL/ToxiCR/tree/master).

#### Шаги выполнения

1. Проведите очистку набора данных, устраняя пропущенные значения и дубликаты.
2. Подготовьте текстовые данные для анализа, выполнив следующие пункты
(опционально, вдохновлено оригинальной работой авторов репозитория):
 - Удаление URL-ссылок, например ссылок на документацию, посты Stackoverflow
 - Исправление сокращиений слов, например doesn’t -> does not и we’re -> we are
 для унификации токенов. (готовый словарь можно найти в репозитории ToxiCR)
 - Удаление повторяющихся символов: “You’re duumbbbb!,” -> “you are dumb”
 - Удаление специальных символов &, #, ^, *...
 - Исправление специально испорченных ругательных слов (словарь с регулярными
 выражениями также можно найти в репозитории ToxiCR)
 - Ваши предложения по очистке датасета...
3. После предобработки сохраните подготовленные данные для дальнейшего
использования

### Подзадача 2: Использование моделей машинного обучения для классификации комментариев

**Цель**: Попробовать набор различных подходов к классификации текстов.

**Модели**:

 - Классические модели (Logistic Regression, Random Forest)
 - [**RoBERTa**](https://huggingface.co/FacebookAI/roberta-base)
 - [**CodeBERT**](https://huggingface.co/microsoft/codebert-base):
    предобученная модель трансформер семейства BERT, адаптированная для
    работы с исходным кодом.

#### Шаги выполнения

##### Использование классических методов машинного обучения (библиотека [**scikit-learn**](https://scikit-learn.org/stable/supervised_learning.html))

1. Для преобразования в числовое представление ранее подготовленных текстов
используйте CountVectorizer и/или TfidfVectorizer.
2. Обучите модели Random Forest и/или Logistic Regression на полученных
CountVectorizer и/или TfidfVectorizer.
3. Проведите оценку качества моделей путем 10-фолдовой кросс-валидации (KFold cross-validation)
4. Постройте и проанализируйте матрицу несоответствия (confusion matrix).
5. Попробуйте улучшить качество классификации путем экспериментов с
гипер-параметрами моделей и методов для извлечения признаков.

##### Использование предобученных моделей (библиотека [**transformers**](https://huggingface.co/docs/transformers/tasks/sequence_classification))

1. Используйте токенизатор RoBERTa (CodeBERT) для преобразования текстовых
данных в формат, понятный модели.
2. Инициализируйте модель RoBERTa/CodeBERT
(`AutoModelForSequenceClassification`) и объект Trainer, который будет
управлять процессом обучения. Определите параметры обучения, такие как
количество эпох, размер батча и скорость обучения. Запустите процесс обучения
модели на обучающих данных.
3. Оцените качество модели метриками `accuracy`, `precision_recall_fscore_support`,
добавив в Trainer параметр `compute_metrics`, реализовав соответствующие метрики.
4. Подготовьте краткий (1-2 стр.) отчет, который будет включать сравнение по
метрикам accuracy, precision, recall, f1-score всех реализованных моделей на
отложенном eval наборе данных.


### Сроки выполнения

Общий срок выполнения задания: 2 недели

### Дополнительные указания

- При выполнения задания создайте репозиторий на GitHub, в котором будет находиться текущий шаблон и весь код реализации
- Решение может быть выполнено как в виде модулей на языке Python так и в виде Jupyter Notebook'ов.
- Используйте виртуальное окружение для установки всех зависимостей, большинство зависимостей уже зафиксировано в шаблоне
- В отчете опишите все проблемы, с которыми вы столкнулись, и как вы их решили.
